{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_Fine_Grained_One_vs_Rest_Approach.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx2rj4jmOvJL"
      },
      "source": [
        "# For Fake, Hate, Offensive Datasets\n",
        "\n",
        "# Code Objective:\n",
        "\n",
        "*   mBERT Model for Fine Grained Evaluation\n",
        "*   Constructing Problem from Multilabel Classification to independent Binary Classification\n",
        "\n",
        "# Code Results:\n",
        "*   Accuracy - mBERT Model for Fake vs Non-Fake = 81.38 %\n",
        "*   Accuracy - mBERT Model for Hate vs Non-Hate = 77.12 %\n",
        "*   Accuracy - mBERT Model for Defamation vs Non-Defamation = 79.52 %\n",
        "*   Accuracy - mBERT Model for Offensive vs Non-Offensive = 69.68 %\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dWCw-Y5PuXQ"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvMlDjs63TBG"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_ppFOaeJxHD"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json, re\n",
        "from tqdm import tqdm_notebook\n",
        "from uuid import uuid4\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import glue_compute_metrics\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaConfig, XLMRobertaForSequenceClassification\n",
        "\n",
        "print(\"GPU Torch Available = {}\".format(torch.cuda.is_available()))\n",
        "print(\"Torch Version = {}\".format(torch.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiO16rxYP0lF"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlZhZHC9YG4a"
      },
      "source": [
        "'''\n",
        "Loading Dataset for Finegrained Multilabel Evaluation which has been transformed\n",
        "as multiple independent binary classification (One vs Rest Approach)\n",
        "'''\n",
        "\n",
        "dataset = 'Fake'             # Choosing Dataset to Load\n",
        "\n",
        "if dataset == 'Fake':\n",
        "  # Training Data\n",
        "  file = '/content/fake_train.xlsx'\n",
        "  train_df = pd.read_excel(file)\n",
        "  # Validation Data\n",
        "  file = '/content/fake_validate.xlsx'\n",
        "  test_df = pd.read_excel(file)\n",
        "  test_df\n",
        "\n",
        "elif dataset == 'Hate':\n",
        "  # Training Data\n",
        "  file = '/content/hate_train.xlsx'\n",
        "  train_df = pd.read_excel(file)\n",
        "  # Validation Data\n",
        "  file = '/content/hate_validate.xlsx'\n",
        "  test_df = pd.read_excel(file)\n",
        "  test_df\n",
        "\n",
        "elif dataset == 'Offensive':\n",
        "  # Training Data\n",
        "  file = '/content/offensive_train.xlsx'\n",
        "  train_df = pd.read_excel(file)\n",
        "  # Validation Data\n",
        "  file = '/content/offensive_validate.xlsx'\n",
        "  test_df = pd.read_excel(file)\n",
        "  test_df\n",
        "\n",
        "else:\n",
        "  print('Choose Correct Dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPPD7q2_YM55"
      },
      "source": [
        "# Data Preparation into Pandas Dataframe for Model Input\n",
        "\n",
        "def get_data(a):\n",
        "  Unique_ID = list(a['Unique ID'])\n",
        "  sentence = list(a['Post'])\n",
        "  text_labels = list(a['Labels Set'])\n",
        "\n",
        "  label = []\n",
        "  for i in text_labels:\n",
        "    if i=='non_offensive':\n",
        "        label.append(0)\n",
        "    elif i=='offensive':\n",
        "        label.append(1)\n",
        "    elif i=='non_fake':\n",
        "        label.append(0)\n",
        "    elif i=='fake':\n",
        "        label.append(1)\n",
        "    elif i=='non_hate':\n",
        "        label.append(0)\n",
        "    elif i=='hate':\n",
        "        label.append(1)\n",
        "\n",
        "  raw_data_train = {'UID':Unique_ID,'sentence': sentence, 'label': label}\n",
        "  df = pd.DataFrame(raw_data_train, columns = ['UID','sentence','label'])\n",
        "  return df\n",
        "\n",
        "train_data = get_data(train_df)\n",
        "test_data  = get_data(test_df)\n",
        "\n",
        "print(train_data[0:3])\n",
        "print(test_data[0:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-LBlN9xStzh"
      },
      "source": [
        "# Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ALqUM9f5Qnx"
      },
      "source": [
        "if (model_name == 'Bert'):\n",
        "  # Bert Parameters\n",
        "  config = BertConfig.from_pretrained('bert-base-multilingual-cased',num_labels=2)\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "  model = BertForSequenceClassification(config)\n",
        "  print('BERT Model Loaded')\n",
        "else:\n",
        "  print('Choose correct Model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Xsy7ghkSvyf"
      },
      "source": [
        "# Data Preparation for Model Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf0ATRkF5LEx"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.sentence = dataframe.sentence\n",
        "        self.targets = self.data.label\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentence)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sentence1 = str(self.sentence[index])\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(sentence1,\n",
        "                                            truncation=True,\n",
        "                                            add_special_tokens=True,\n",
        "                                            max_length=self.max_len,\n",
        "                                            pad_to_max_length=True,\n",
        "                                            return_token_type_ids=True)\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        return {'input_ids': torch.tensor(ids, dtype=torch.long),\n",
        "                'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
        "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "                'labels': torch.tensor(self.targets[index], dtype=torch.long)\n",
        "               }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDx-QxmX5Muc"
      },
      "source": [
        "# Dataset for Input into Model\n",
        "MAX_LEN = 128                                                 # Max Sequence Length\n",
        "training_set = CustomDataset(train_data, tokenizer, MAX_LEN)  # Training Set\n",
        "testing_set = CustomDataset(test_data, tokenizer, MAX_LEN)    # Validation Set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnQH2cqlTRoU"
      },
      "source": [
        "# Training and Evaluation Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ia34HohXuSU"
      },
      "source": [
        "# Device Mapping Select (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.cuda()\n",
        "\n",
        "# Training Arguments\n",
        "training_args = TrainingArguments(output_dir=\"./models/model_name\",\n",
        "                                  overwrite_output_dir=True,\n",
        "                                  do_train=True,\n",
        "                                  do_eval=True,\n",
        "                                  per_device_train_batch_size=28,\n",
        "                                  per_device_eval_batch_size=28,\n",
        "                                  num_train_epochs=20,\n",
        "                                  logging_steps=100,\n",
        "                                  logging_first_step=True,\n",
        "                                  save_steps=0,\n",
        "                                  evaluation_strategy ='epoch')\n",
        "\n",
        "# Metric for Performance Evaluation\n",
        "def compute_metrics(p):\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  return glue_compute_metrics(\"mnli\", preds, p.label_ids)\n",
        "\n",
        "# Trainer for training Model\n",
        "trainer = Trainer(model = model,\n",
        "                  args = training_args,\n",
        "                  train_dataset = training_set,\n",
        "                  eval_dataset = testing_set,\n",
        "                  compute_metrics = compute_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v84hu3rWXzz8"
      },
      "source": [
        "# Training Model\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRnlRPCkZ3-s"
      },
      "source": [
        "# Evaluation of Model on Validation Data\n",
        "trainer.evaluate(testing_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1639h8QPW0Z6"
      },
      "source": [
        "# Trained Model Save and Load for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8-c3xRdayNC"
      },
      "source": [
        "# Model Save\n",
        "model_save_path = '/content/BERT_state_dict_' + dataset + '_'\n",
        "torch.save(model.state_dict(), model_save_path + str(uuid4())+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjY2SE3nt6o-"
      },
      "source": [
        "# Model Load\n",
        "model_path = '/content/XLMR_state_dict_offensive_de181722-b72b-4ea0-9713-27769728db16.pth'\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOOA69dLXLUk"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpV2-snhjnR4"
      },
      "source": [
        "'''\n",
        "Load Model, predict on validation or test data and get labels for each dataset\n",
        "For 3 different datasets (Fake, Hate, Offensive) \n",
        "we get 3 output numpy array of labels. \n",
        "'''\n",
        "\n",
        "# Prediction\n",
        "def prepare_features(seq_1, max_seq_length = 128, zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
        "    ## Tokenzine Input\n",
        "    tokens_a = tokenizer.tokenize(seq_1)\n",
        "\n",
        "    ## Truncate\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "    ## Initialize Tokens\n",
        "    tokens = []\n",
        "    if include_CLS_token:\n",
        "        tokens.append(tokenizer.cls_token)\n",
        "    ## Add Tokens and separators\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "\n",
        "    if include_SEP_token:\n",
        "        tokens.append(tokenizer.sep_token)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    ## Input Mask \n",
        "    input_mask = [1] * len(input_ids)\n",
        "    ## Zero-pad sequence lenght\n",
        "    if zero_pad:\n",
        "        while len(input_ids) < max_seq_length:\n",
        "            input_ids.append(0)\n",
        "            input_mask.append(0)\n",
        "    return torch.tensor(input_ids).unsqueeze(0), input_mask\n",
        "\n",
        "\n",
        "def predict(text):\n",
        "  model.eval()\n",
        "  input_feature, _ = prepare_features(text)\n",
        "  if torch.cuda.is_available():\n",
        "    input_feature = input_feature.cuda()\n",
        "  output = model(input_feature)[0]\n",
        "  _, pred_label = torch.max(output.data, 1)\n",
        "  prediction = pred_label[0].item()\n",
        "  if (prediction == 0):\n",
        "    return 'non_offensive',0\n",
        "  else:\n",
        "    return 'offensive',1\n",
        "\n",
        "data = test_data\n",
        "\n",
        "pred = []\n",
        "pred_lab = []\n",
        "for i in range(len(data)):\n",
        "  text = data['sentence'][i]\n",
        "  pred_text , pred_label = predict(text)\n",
        "  pred.append(pred_text)\n",
        "  pred_lab.append(pred_label)\n",
        "\n",
        "pred_lab = np.array(pred_lab, dtype=np.float)\n",
        "np.save('Final_Offensive_validation_Pred_Label.npy',pred_lab)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
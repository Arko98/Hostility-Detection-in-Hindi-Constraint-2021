{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Coarse_Grained_Models_(BERT_and_Roberta).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXnV9dwF50Yd"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvMlDjs63TBG"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_ppFOaeJxHD"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json, re\n",
        "from tqdm import tqdm_notebook\n",
        "from uuid import uuid4\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import glue_compute_metrics\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaConfig, XLMRobertaForSequenceClassification\n",
        "\n",
        "print(\"GPU Torch Available = {}\".format(torch.cuda.is_available()))\n",
        "print(\"Torch Version = {}\".format(torch.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stY-Wn8U56mT"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlZhZHC9YG4a"
      },
      "source": [
        "# Loading Training Data\n",
        "file = '/content/bin_train.xlsx'\n",
        "train_df = pd.read_excel(file)\n",
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpq87FQrYLQg"
      },
      "source": [
        "# Loading Validation Data\n",
        "file = '/content/bin_validate.xlsx'\n",
        "test_df = pd.read_excel(file)\n",
        "test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPPD7q2_YM55"
      },
      "source": [
        "# Data Preparation into Pandas Dataframe for Model Input\n",
        "def get_data(a):\n",
        "  Unique_ID = list(a['Unique ID'])\n",
        "  sentence = list(a['Post'])\n",
        "  text_labels = list(a['Labels Set'])\n",
        "\n",
        "  label = []\n",
        "  for i in text_labels:\n",
        "    if i=='non-hostile':\n",
        "        label.append(0)\n",
        "    elif i=='hostile':\n",
        "        label.append(1)\n",
        "\n",
        "  raw_data_train = {'UID':Unique_ID,'sentence': sentence, 'label': label}\n",
        "  df = pd.DataFrame(raw_data_train, columns = ['UID','sentence','label'])\n",
        "  return df,label\n",
        "\n",
        "train_data,train_label = get_data(train_df)\n",
        "test_data,test_label  = get_data(test_df)\n",
        "\n",
        "\n",
        "print(train_data[0:3])\n",
        "print(test_data[0:3])\n",
        "\n",
        "np.array(train_label).dump(open('Train_Labels.npy', 'wb'))\n",
        "np.array(test_label).dump(open('Test_Labels.npy', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKYQMf1D6KhK"
      },
      "source": [
        "# Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ALqUM9f5Qnx"
      },
      "source": [
        "# Choose and Load Model\n",
        "model_name = 'XLMR'\n",
        "\n",
        "if (model_name = 'XLMR'):\n",
        "  # XLMRoberta Parameters\n",
        "  config = XLMRobertaConfig.from_pretrained('xlm-roberta-base',num_labels=2)\n",
        "  tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "  model = XLMRobertaForSequenceClassification(config)\n",
        "  print('XLMR Model Loaded')\n",
        "else:\n",
        "  print('Choose correct Model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP_wD20y8XmK"
      },
      "source": [
        "# Data Preparation for Model Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf0ATRkF5LEx"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.sentence = dataframe.sentence\n",
        "        self.targets = self.data.label\n",
        "        self.max_len = max_len\n",
        "    def __len__(self):\n",
        "        return len(self.sentence)\n",
        "    def __getitem__(self, index):\n",
        "        sentence1 = str(self.sentence[index])\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(sentence1,\n",
        "                                            truncation=True,\n",
        "                                            add_special_tokens=True,\n",
        "                                            max_length=self.max_len,\n",
        "                                            pad_to_max_length=True,\n",
        "                                            return_token_type_ids=True)\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        return {'input_ids': torch.tensor(ids, dtype=torch.long),\n",
        "                'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
        "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "                'labels': torch.tensor(self.targets[index], dtype=torch.long)\n",
        "               }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDx-QxmX5Muc"
      },
      "source": [
        "# Dataset for Input into Model\n",
        "MAX_LEN = 128                                                # Max Sequence Length\n",
        "training_set = CustomDataset(train_data, tokenizer, MAX_LEN) # Training Set\n",
        "testing_set = CustomDataset(test_data, tokenizer, MAX_LEN)   # Validation Set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wE8FwQL8GBE"
      },
      "source": [
        "# Training and Evaluation Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ia34HohXuSU"
      },
      "source": [
        "# Device Mapping Select (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.cuda()\n",
        "\n",
        "# Training Arguments\n",
        "training_args = TrainingArguments(output_dir=\"./models/model_name\",\n",
        "                                  overwrite_output_dir=True,\n",
        "                                  do_train=True,\n",
        "                                  do_eval=True,\n",
        "                                  per_device_train_batch_size=28,\n",
        "                                  per_device_eval_batch_size=28,\n",
        "                                  num_train_epochs=20,\n",
        "                                  logging_steps=100,\n",
        "                                  logging_first_step=True,\n",
        "                                  save_steps=0,\n",
        "                                  evaluation_strategy  = 'epochs')\n",
        "\n",
        "# Metric for Performance Evaluation\n",
        "def compute_metrics(p):\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  return glue_compute_metrics(\"mnli\", preds, p.label_ids)\n",
        "\n",
        "# Trainer for training Model\n",
        "trainer = Trainer(model = model,\n",
        "                  args = training_args,\n",
        "                  train_dataset = training_set,\n",
        "                  eval_dataset = testing_set,\n",
        "                  compute_metrics = compute_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKgYNLvn_OcW"
      },
      "source": [
        "# Model Load (Load Already Finetuned Model)\r\n",
        "model_load_path = '/content/XLMR_state_dict_Coarse.pth'\r\n",
        "model.load_state_dict(torch.load(model_load_path, map_location=device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v84hu3rWXzz8"
      },
      "source": [
        "# Training Model (If you want fresh finetune run this cell without loading already finetuned model)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRnlRPCkZ3-s"
      },
      "source": [
        "# Evaluation of Model on Validation Data\n",
        "trainer.evaluate(testing_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxBJCIwR-1Fx"
      },
      "source": [
        "# Trained Model Save and Load for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8-c3xRdayNC"
      },
      "source": [
        "# Model Save (Fresh Finetuned Model Save)\n",
        "model_name = 'XLMR'\n",
        "model_save_path = '/content/' + model_name +'_state_dict_'\n",
        "torch.save(model.state_dict(), model_save_path + str(uuid4()) + '.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9iW-9g--9up"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIegEYr8Ya-0"
      },
      "source": [
        "def prepare_features(seq_1, max_seq_length = 128, zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
        "    ## Tokenzine Input\n",
        "    tokens_a = tokenizer.tokenize(seq_1)\n",
        "\n",
        "    ## Truncate\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "    ## Initialize Tokens\n",
        "    tokens = []\n",
        "    if include_CLS_token:\n",
        "        tokens.append(tokenizer.cls_token)\n",
        "    ## Add Tokens and separators\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "\n",
        "    if include_SEP_token:\n",
        "        tokens.append(tokenizer.sep_token)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    ## Input Mask \n",
        "    input_mask = [1] * len(input_ids)\n",
        "    ## Zero-pad sequence lenght\n",
        "    if zero_pad:\n",
        "        while len(input_ids) < max_seq_length:\n",
        "            input_ids.append(0)\n",
        "            input_mask.append(0)\n",
        "    return torch.tensor(input_ids).unsqueeze(0), input_mask\n",
        "\n",
        "def predict(text):\n",
        "  model.eval()\n",
        "  input_feature, _ = prepare_features(text)\n",
        "  if torch.cuda.is_available():\n",
        "    input_feature = input_feature.cuda()\n",
        "  output = model(input_feature)[0]\n",
        "  _, pred_label = torch.max(output.data, 1)\n",
        "  prediction = pred_label\n",
        "  return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9p7gIEbBnOA"
      },
      "source": [
        "# Prediction Probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4FCS_a1_EUC"
      },
      "source": [
        "def predict_looper(text):\n",
        "  model.eval()\n",
        "  input_feature, _ = prepare_features(text)\n",
        "  if torch.cuda.is_available():\n",
        "    input_feature = input_feature.cuda()\n",
        "  output = model(input_feature)[0]\n",
        "  Softmax = nn.Softmax(dim=1)\n",
        "  prob = Softmax(output)\n",
        "  prob_cpu = prob.cpu().detach().numpy()\n",
        "  return prob_cpu[0]\n",
        "\n",
        "data_1 = train_data\n",
        "data_2 = test_data\n",
        "\n",
        "pred_1 = []\n",
        "for i in range(len(data_1)):\n",
        "  text = data_1['sentence'][i]\n",
        "  pred_1.append(predict_looper(text))\n",
        "\n",
        "pred_2 = []\n",
        "for i in range(len(data_2)):\n",
        "  text = data_2['sentence'][i]\n",
        "  pred_2.append(predict_looper(text))\n",
        "\n",
        "y1 = np.array(pred_1)\n",
        "y2 = np.array(pred_2)\n",
        "\n",
        "np.array(y1).dump(open('Train_Probs_Coarse_XLMR.npy', 'wb')) # Training Probabilities\n",
        "np.array(y2).dump(open('Test_Probs_Coarse_XLMR.npy', 'wb'))  # Testing Probabilities"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
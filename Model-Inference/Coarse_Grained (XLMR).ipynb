{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Coarse_Grained_Models_(BERT_and_Roberta).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXnV9dwF50Yd"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvMlDjs63TBG"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_ppFOaeJxHD"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json, re\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import glue_compute_metrics\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaConfig, XLMRobertaForSequenceClassification\n",
        "\n",
        "print(\"GPU Torch Available = {}\".format(torch.cuda.is_available()))\n",
        "print(\"Torch Version = {}\".format(torch.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stY-Wn8U56mT"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlZhZHC9YG4a"
      },
      "source": [
        "# Loading Training Data\n",
        "file = '/content/bin_train.xlsx'\n",
        "train_df = pd.read_excel(file)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sNYze_oPc01"
      },
      "source": [
        "# Loading Validation Data (Run when evaluating for Validation Data)\r\n",
        "file = '/content/Validation.xlsx'       # Cleaned Validation Data (Obtained After Preprocessing the Original Validation Data from Organizers)\r\n",
        "test_df = pd.read_excel(file)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpq87FQrYLQg"
      },
      "source": [
        "# Loading Testing Data    (Run when evaluating for Test Data)\n",
        "file = '/content/Hindi_Test.xlsx'       # Cleaned Test Data (Obtained After Preprocessing the Original Test Data from Organizers)\n",
        "test_df = pd.read_excel(file, names = ['Row','Unique ID','Post'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPPD7q2_YM55"
      },
      "source": [
        "# Data Preparation into Pandas Dataframe for Model Input\n",
        "def get_data(a):\n",
        "  Unique_ID = list(a['Unique ID'])\n",
        "  sentence = list(a['Post'])\n",
        "\n",
        "  # Appending Dummy Labels as Labels are not needed\n",
        "  label = []\n",
        "  for i in Unique_ID:\n",
        "    label.append(0)    \n",
        "  \n",
        "  raw_data_train = {'UID':Unique_ID,'sentence': sentence, 'label': label}\n",
        "  df = pd.DataFrame(raw_data_train, columns = ['UID','sentence','label'])\n",
        "  return df\n",
        "\n",
        "train_data = get_data(train_df)\n",
        "test_data  = get_data(test_df)\n",
        "\n",
        "print(train_data[0:3])\n",
        "print(test_data[0:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKYQMf1D6KhK"
      },
      "source": [
        "# Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ALqUM9f5Qnx"
      },
      "source": [
        "# Choose and Load Model\n",
        "model_name = 'XLMR'\n",
        "\n",
        "if (model_name == 'XLMR'):\n",
        "  # XLMRoberta Parameters\n",
        "  config = XLMRobertaConfig.from_pretrained('xlm-roberta-base',num_labels=2)\n",
        "  tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "  model = XLMRobertaForSequenceClassification(config)\n",
        "  print('XLMR Model Loaded')\n",
        "else:\n",
        "  print('Choose correct Model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP_wD20y8XmK"
      },
      "source": [
        "# Data Preparation for Model Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf0ATRkF5LEx"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.sentence = dataframe.sentence\n",
        "        self.targets = self.data.label\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.sentence)\n",
        "    def __getitem__(self, index):\n",
        "        sentence1 = str(self.sentence[index])\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(sentence1,\n",
        "                                            truncation=True,\n",
        "                                            add_special_tokens=True,\n",
        "                                            max_length=self.max_len,\n",
        "                                            pad_to_max_length=True,\n",
        "                                            return_token_type_ids=True)\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        return {'input_ids': torch.tensor(ids, dtype=torch.long),\n",
        "                'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
        "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "                'labels': torch.tensor(self.targets[index], dtype=torch.long)\n",
        "               }"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDx-QxmX5Muc"
      },
      "source": [
        "# Dataset for Input into Model\n",
        "MAX_LEN = 128                                                # Max Sequence Length\n",
        "training_set = CustomDataset(train_data, tokenizer, MAX_LEN) # Training Set\n",
        "testing_set = CustomDataset(test_data, tokenizer, MAX_LEN)   # Validation Set"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wE8FwQL8GBE"
      },
      "source": [
        "# Training and Evaluation Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ia34HohXuSU"
      },
      "source": [
        "# Device Mapping Select (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.cuda()\n",
        "\n",
        "# Training Arguments\n",
        "training_args = TrainingArguments(output_dir=\"./models/model_name\",\n",
        "                                  overwrite_output_dir=True,\n",
        "                                  do_train=True,\n",
        "                                  do_eval=True,\n",
        "                                  per_device_train_batch_size=28,\n",
        "                                  per_device_eval_batch_size=28,\n",
        "                                  num_train_epochs=20,\n",
        "                                  logging_steps=100,\n",
        "                                  logging_first_step=True,\n",
        "                                  save_steps=0,\n",
        "                                  evaluation_strategy  = 'epoch')\n",
        "\n",
        "# Metric for Performance Evaluation\n",
        "def compute_metrics(p):\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  return glue_compute_metrics(\"mnli\", preds, p.label_ids)\n",
        "\n",
        "# Trainer for training Model\n",
        "trainer = Trainer(model = model,\n",
        "                  args = training_args,\n",
        "                  train_dataset = training_set,\n",
        "                  eval_dataset = testing_set,\n",
        "                  compute_metrics = compute_metrics)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1sOEc_NP6l4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKgYNLvn_OcW"
      },
      "source": [
        "# Model Load (Load Already Finetuned Model)\r\n",
        "model_load_path = '/content/drive/MyDrive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Weights/XLMR_state_dict_Coarse.pth'\r\n",
        "model.load_state_dict(torch.load(model_load_path, map_location=device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9iW-9g--9up"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIegEYr8Ya-0"
      },
      "source": [
        "def prepare_features(seq_1, max_seq_length = 128, zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
        "    ## Tokenzine Input\n",
        "    tokens_a = tokenizer.tokenize(seq_1)\n",
        "\n",
        "    ## Truncate\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "    ## Initialize Tokens\n",
        "    tokens = []\n",
        "    if include_CLS_token:\n",
        "        tokens.append(tokenizer.cls_token)\n",
        "    ## Add Tokens and separators\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "\n",
        "    if include_SEP_token:\n",
        "        tokens.append(tokenizer.sep_token)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    ## Input Mask \n",
        "    input_mask = [1] * len(input_ids)\n",
        "    ## Zero-pad sequence lenght\n",
        "    if zero_pad:\n",
        "        while len(input_ids) < max_seq_length:\n",
        "            input_ids.append(0)\n",
        "            input_mask.append(0)\n",
        "    return torch.tensor(input_ids).unsqueeze(0), input_mask\n",
        "\n",
        "def predict(text):\n",
        "  model.eval()\n",
        "  input_feature, _ = prepare_features(text)\n",
        "  if torch.cuda.is_available():\n",
        "    input_feature = input_feature.cuda()\n",
        "  output = model(input_feature)[0]\n",
        "  _, pred_label = torch.max(output.data, 1)\n",
        "  prediction = pred_label\n",
        "  return prediction"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9p7gIEbBnOA"
      },
      "source": [
        "# Prediction Probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4FCS_a1_EUC"
      },
      "source": [
        "def predict_looper(text):\n",
        "  model.eval()\n",
        "  input_feature, _ = prepare_features(text)\n",
        "  if torch.cuda.is_available():\n",
        "    input_feature = input_feature.cuda()\n",
        "  output = model(input_feature)[0]\n",
        "  Softmax = nn.Softmax(dim=1)\n",
        "  prob = Softmax(output)\n",
        "  prob_cpu = prob.cpu().detach().numpy()\n",
        "  return prob_cpu[0]\n",
        "\n",
        "data = test_data\n",
        "\n",
        "pred = []\n",
        "for i in range(len(data)):\n",
        "  text = data['sentence'][i]\n",
        "  pred.append(predict_looper(text))\n",
        "\n",
        "y = np.array(pred)\n",
        "\n",
        "np.array(y).dump(open('Test_Probs_Coarse_XLMR.npy', 'wb'))  # Testing Probabilities"
      ],
      "execution_count": 29,
      "outputs": []
    }
  ]
}